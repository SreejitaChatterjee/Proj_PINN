% IEEE Conference Paper Template
% Focus: Architecture-Dependent Parameter Identification in PINNs
% Target: CDC 2026 / L4DC / ACC

\documentclass[conference]{IEEEtran}

\IEEEoverridecommandlockouts

\usepackage{graphics}
\usepackage{graphicx}
\usepackage{amsmath,amssymb}
\usepackage{booktabs}
\usepackage{cite}
\usepackage{url}
\usepackage[hidelinks]{hyperref}
\usepackage{xcolor}
\usepackage{multirow}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{amsthm}
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}{Proposition}
\newtheorem{remark}{Remark}

\title{\LARGE \bf
Architecture-Dependent Parameter Identification in Physics-Informed Neural Networks: Decoupling Dynamics Prediction from System Identification
}

\author{[Author Name]$^{1}$%
\thanks{$^{1}$[Author] is with [Department], [University], [Address]. {\tt\small email@institution.edu}}%
}

\begin{document}

\maketitle
\thispagestyle{empty}
\pagestyle{empty}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}

Physics-Informed Neural Networks (PINNs) simultaneously learn dynamics and identify physical parameters. While prior work optimizes architectures for prediction accuracy, we discover that \textit{architectural choices have dramatically different effects on dynamics prediction versus parameter identification}. Through systematic experiments on 6-DOF quadrotor dynamics, we reveal three surprising findings: (1) Modular architectures that separate translational/rotational dynamics achieve 5$\times$ better mass identification (7.7\% vs 40\% error) while also improving prediction stability; (2) Curriculum-trained networks achieve 7$\times$ better inertia identification (7--8\% vs 52--60\% error) despite having worse dynamics prediction; (3) Fourier feature embeddings improve specific inertia identification (32\% vs 60\% for $J_{xx}$) while degrading others. These results demonstrate that dynamics prediction and parameter identification are \textit{decoupled objectives} that respond differently to architectural choices. We formalize this as the \textit{prediction-identification tradeoff} and provide guidelines for architecture selection based on application requirements.

\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{INTRODUCTION}

Physics-Informed Neural Networks (PINNs)~\cite{raissi2019physics} embed governing equations into neural network training, enabling simultaneous dynamics learning and physical parameter identification. This dual capability makes PINNs attractive for robotics applications where both accurate prediction and system identification are valuable.

Prior work has extensively studied how architectural choices affect \textit{prediction accuracy}---particularly for autoregressive rollout where predictions feed back as inputs~\cite{serrano2024physics}. However, the effect of architecture on \textit{parameter identification} has received little attention, with an implicit assumption that better prediction implies better identification.

\textbf{We challenge this assumption.} Through systematic experiments on quadrotor dynamics, we discover that architectural choices have dramatically different---and sometimes opposing---effects on dynamics prediction versus parameter identification.

\subsection{Motivating Example}

Consider two PINN architectures for quadrotor dynamics:
\begin{itemize}
    \item \textbf{Modular}: Separate subnetworks for translation and rotation
    \item \textbf{Curriculum}: Monolithic network with multi-step training
\end{itemize}

For \textit{dynamics prediction}, Modular achieves 4.6$\times$ better 100-step stability (1.11m vs 5.09m MAE). However, for \textit{inertia identification}, Curriculum achieves 7$\times$ better accuracy (7--8\% vs 52--60\% error). Neither architecture dominates both objectives.

\subsection{Contributions}

This paper makes three contributions:

\begin{enumerate}
    \item \textbf{Decoupling Discovery}: We demonstrate that dynamics prediction and parameter identification respond differently to architectural choices, with some architectures excelling at one while degrading the other (Section~\ref{sec:results}).

    \item \textbf{Architecture-Specific Identification}: We characterize which architectures identify which parameters: modular improves mass identification (5$\times$), curriculum improves inertia identification (7$\times$), and Fourier features selectively improve $J_{xx}$ (2$\times$) (Section~\ref{sec:analysis}).

    \item \textbf{Prediction-Identification Tradeoff}: We formalize the tradeoff between prediction accuracy and identification accuracy, providing guidelines for architecture selection based on application requirements (Section~\ref{sec:tradeoff}).
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{PROBLEM FORMULATION}

\subsection{PINN Dynamics Learning}

Consider a dynamical system with state $\mathbf{x} \in \mathbb{R}^n$, control $\mathbf{u} \in \mathbb{R}^m$, and physical parameters $\boldsymbol{\theta} \in \mathbb{R}^p$:
\begin{equation}
\dot{\mathbf{x}} = f(\mathbf{x}, \mathbf{u}; \boldsymbol{\theta})
\end{equation}

A PINN learns a neural network $g_\phi$ that predicts state transitions while simultaneously learning parameter estimates $\hat{\boldsymbol{\theta}}$:
\begin{equation}
\hat{\mathbf{x}}_{t+1} = g_\phi(\mathbf{x}_t, \mathbf{u}_t; \hat{\boldsymbol{\theta}})
\end{equation}

The training loss combines data fitting and physics consistency:
\begin{equation}
\mathcal{L} = \underbrace{\|\hat{\mathbf{x}}_{t+1} - \mathbf{x}_{t+1}\|^2}_{\text{Prediction}} + \lambda_p \underbrace{\left\|\frac{\hat{\mathbf{x}}_{t+1} - \mathbf{x}_t}{\Delta t} - f(\mathbf{x}_t, \mathbf{u}_t; \hat{\boldsymbol{\theta}})\right\|^2}_{\text{Physics}}
\end{equation}

\subsection{Dual Objectives}

PINNs optimize two distinct objectives:

\textbf{Objective 1: Dynamics Prediction.} Minimize prediction error over $K$-step autoregressive rollout:
\begin{equation}
\mathcal{E}_{\text{pred}}^{(K)} = \mathbb{E}\left[\|\hat{\mathbf{x}}_{t+K} - \mathbf{x}_{t+K}\|\right]
\end{equation}

\textbf{Objective 2: Parameter Identification.} Minimize parameter estimation error:
\begin{equation}
\mathcal{E}_{\text{id}} = \|\hat{\boldsymbol{\theta}} - \boldsymbol{\theta}^*\| / \|\boldsymbol{\theta}^*\|
\end{equation}

\textbf{Key Question}: Do architectural choices that improve $\mathcal{E}_{\text{pred}}$ also improve $\mathcal{E}_{\text{id}}$?

\subsection{Experimental System}

We study a 6-DOF quadrotor with 12-dimensional state and 6 physical parameters:
\begin{equation}
\boldsymbol{\theta} = [m, k_t, k_q, J_{xx}, J_{yy}, J_{zz}]^T
\end{equation}

The dynamics exhibit strong coupling between parameters:
\begin{align}
\ddot{z} &= -\frac{T\cos\theta\cos\phi}{m} + g \\
\dot{p} &= \frac{(J_{yy} - J_{zz})qr + \tau_x}{J_{xx}}
\end{align}

Mass $m$ appears in translational dynamics; inertias $J_{xx}, J_{yy}, J_{zz}$ appear in rotational dynamics with cross-coupling.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{ARCHITECTURAL VARIANTS}

We evaluate four PINN architectures with identical physics constraints:

\subsection{Baseline: Monolithic MLP}
Standard 5-layer MLP (256 neurons) processing full state-control input. Parameters: 204,818.

\subsection{Modular: Separated Subsystems}
Independent subnetworks for translational ($z, v_z$) and rotational ($\phi, \theta, \psi, p, q, r$) dynamics. Shared input encoding, separate prediction heads. Parameters: 71,954.

\textbf{Design rationale}: Physics-informed separation matching the structure of Newton-Euler equations.

\subsection{Fourier: Periodic Embeddings}
Fourier feature encoding for angular states:
\begin{equation}
\gamma(\theta) = [\sin(\omega_k\theta), \cos(\omega_k\theta)]_{k=1}^K
\end{equation}
with frequencies $\omega_k = 2^{k-1}$, $K=8$. Parameters: 302,354.

\textbf{Design rationale}: Capture periodic structure of rotational dynamics.

\subsection{Curriculum: Multi-Step Training}
Monolithic architecture trained with progressively increasing rollout horizons (5$\to$10$\to$25$\to$50 steps) and scheduled sampling. Parameters: 204,818.

\textbf{Design rationale}: Optimize for long-horizon prediction stability.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{EXPERIMENTAL RESULTS}
\label{sec:results}

\subsection{Setup}

\textbf{Data}: 10 quadrotor trajectories with square-wave attitude references ($\pm 20^{\circ}$), 49,382 samples at 1kHz. 80/20 train/test split.

\textbf{Metrics}: Single-step MAE, 100-step autoregressive MAE, and parameter identification error versus ground truth.

\subsection{Main Result: Prediction vs. Identification Decoupling}

Table~\ref{tab:main} reveals the central finding: \textit{prediction accuracy and identification accuracy are decoupled}.

\begin{table}[t]
\centering
\caption{Dynamics Prediction vs. Parameter Identification}
\label{tab:main}
\begin{tabular}{lccc}
\toprule
& \textbf{100-Step} & \textbf{Mass} & \textbf{Avg Inertia} \\
\textbf{Architecture} & \textbf{Pos MAE (m)} & \textbf{Error (\%)} & \textbf{Error (\%)} \\
\midrule
Baseline & 5.09 & 40.0 & 57.5 \\
\textbf{Modular} & \textbf{1.11} & \textbf{7.7} & 55.9 \\
Fourier & 5.09 & 40.0 & 47.0 \\
Curriculum & 4.36 & 40.0 & \textbf{25.2} \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Key observations}:
\begin{itemize}
    \item \textbf{Modular} achieves best prediction (1.11m) AND best mass ID (7.7\%)
    \item \textbf{Curriculum} achieves best inertia ID (25.2\%) despite mediocre prediction
    \item \textbf{Fourier} provides no prediction benefit but improves average inertia ID
    \item No single architecture dominates both objectives
\end{itemize}

\subsection{Detailed Parameter Identification Results}

Table~\ref{tab:params} shows per-parameter identification accuracy.

\begin{table}[t]
\centering
\caption{Parameter Identification Error by Architecture (\%)}
\label{tab:params}
\begin{tabular}{lcccccc}
\toprule
\textbf{Arch} & $m$ & $k_t$ & $k_q$ & $J_{xx}$ & $J_{yy}$ & $J_{zz}$ \\
\midrule
Baseline & 40.0 & 0.0 & 0.0 & 59.9 & 52.3 & 60.3 \\
\textbf{Modular} & \textbf{7.7} & 0.0 & 0.0 & 60.1 & 47.2 & 60.3 \\
Fourier & 40.0 & 0.0 & 0.0 & \textbf{32.2} & 53.2 & 55.6 \\
Curriculum & 40.0 & 0.0 & 0.0 & 60.3 & \textbf{7.2} & \textbf{8.0} \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Surprising findings}:
\begin{enumerate}
    \item \textbf{Motor coefficients} ($k_t$, $k_q$): All architectures achieve 0\% error---these have direct, unambiguous gradient signals.

    \item \textbf{Mass} ($m$): Only Modular improves identification (7.7\% vs 40\%). Separating translation/rotation isolates the mass gradient signal.

    \item \textbf{Inertias} ($J_{xx}, J_{yy}, J_{zz}$): Architecture-dependent patterns:
    \begin{itemize}
        \item Curriculum dramatically improves $J_{yy}$, $J_{zz}$ (7--8\%)
        \item Fourier improves $J_{xx}$ only (32\%)
        \item Modular slightly improves $J_{yy}$ (47\%)
    \end{itemize}
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{ANALYSIS}
\label{sec:analysis}

\subsection{Why Modular Improves Mass Identification}

In monolithic networks, mass gradients are entangled with attitude prediction errors:
\begin{equation}
\frac{\partial \mathcal{L}}{\partial m} = \frac{\partial \mathcal{L}}{\partial \ddot{z}} \cdot \frac{\partial \ddot{z}}{\partial m} + \underbrace{\frac{\partial \mathcal{L}}{\partial \phi} \cdot \frac{\partial \phi}{\partial m}}_{\text{spurious coupling}}
\end{equation}

The modular architecture eliminates spurious coupling by separating the gradient paths. The translation module receives clean gradients for mass:
\begin{equation}
\frac{\partial \mathcal{L}_{\text{trans}}}{\partial m} = \frac{\partial \mathcal{L}_{\text{trans}}}{\partial \ddot{z}} \cdot \frac{T\cos\theta\cos\phi}{m^2}
\end{equation}

\begin{proposition}[Modular Mass Isolation]
In the modular architecture, the mass gradient is isolated to the translation subnetwork, eliminating interference from rotational prediction errors.
\end{proposition}

\subsection{Why Curriculum Improves Inertia Identification}

Curriculum training with multi-step rollouts provides stronger inertia gradient signals through error accumulation:

\textbf{Single-step training}: Inertia errors produce small, noisy gradients because attitude changes are small over one timestep.

\textbf{Multi-step training}: Inertia errors accumulate over the rollout, producing larger gradient signals:
\begin{equation}
\frac{\partial \mathcal{L}^{(K)}}{\partial J_{xx}} = \sum_{k=1}^{K} \frac{\partial \mathcal{L}_k}{\partial p_k} \cdot \frac{\partial p_k}{\partial J_{xx}} \cdot \prod_{j=k+1}^{K} \frac{\partial p_j}{\partial p_{j-1}}
\end{equation}

The accumulated gradient provides stronger identification signal for weakly-observable parameters.

\begin{proposition}[Curriculum Inertia Amplification]
Multi-step rollout training amplifies inertia gradient signals by a factor proportional to the rollout horizon $K$, improving identification of weakly-observable parameters.
\end{proposition}

\subsection{Why Fourier Selectively Improves $J_{xx}$}

Fourier features with frequencies $\omega_k = 2^{k-1}$ create resonance effects at specific angular frequencies. Roll dynamics ($J_{xx}$) operate at frequencies that align with lower Fourier components, while pitch/yaw ($J_{yy}$, $J_{zz}$) dynamics occur at frequencies that create interference.

\begin{remark}
The selective improvement of $J_{xx}$ by Fourier features suggests a frequency-matching phenomenon between feature encoding and physical dynamics that warrants further investigation.
\end{remark}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{THE PREDICTION-IDENTIFICATION TRADEOFF}
\label{sec:tradeoff}

\subsection{Formal Characterization}

We observe a tradeoff between prediction and identification objectives:

\begin{equation}
\nexists \text{ architecture } A^* : A^* = \arg\min_A \mathcal{E}_{\text{pred}} = \arg\min_A \mathcal{E}_{\text{id}}
\end{equation}

No single architecture minimizes both objectives simultaneously.

\subsection{Pareto Frontier}

Fig.~\ref{fig:pareto} shows the prediction-identification Pareto frontier across architectures.

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{fig_pareto_tradeoff.pdf}
\caption{Prediction-identification Pareto frontier. Modular dominates for prediction + mass ID. Curriculum dominates for inertia ID. No architecture dominates both objectives.}
\label{fig:pareto}
\end{figure}

\subsection{Application-Specific Guidelines}

Based on our findings, we recommend:

\begin{table}[t]
\centering
\caption{Architecture Selection Guidelines}
\label{tab:guidelines}
\begin{tabular}{lc}
\toprule
\textbf{Application Requirement} & \textbf{Recommended} \\
\midrule
MPC / trajectory tracking & Modular \\
Mass identification & Modular \\
Inertia identification & Curriculum \\
Balanced prediction + ID & Modular \\
Single-step filtering & Baseline/Fourier \\
\bottomrule
\end{tabular}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{DISCUSSION}

\subsection{Implications for PINN Design}

Our results challenge the assumption that prediction accuracy implies identification accuracy. Practitioners should:
\begin{enumerate}
    \item Explicitly define whether prediction or identification is the primary objective
    \item Select architecture based on which parameters need accurate identification
    \item Consider ensemble approaches combining architectures for different parameter subsets
\end{enumerate}

\subsection{Connection to Observability Theory}

The architecture-dependent identification results connect to classical observability theory. Motor coefficients ($k_t$, $k_q$) are strongly observable with direct gradient paths. Mass and inertias are weakly observable, requiring architectural choices that amplify their gradient signals.

\subsection{Limitations}

Our study uses simulated quadrotor data. Real-world validation and extension to other dynamical systems remain future work. The theoretical analysis is empirically motivated; rigorous proofs require further development.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{CONCLUSIONS}

We discovered that PINN architectural choices have dramatically different effects on dynamics prediction versus parameter identification:

\begin{enumerate}
    \item \textbf{Modular architectures} achieve 5$\times$ better mass identification (7.7\% vs 40\%) by isolating gradient signals

    \item \textbf{Curriculum training} achieves 7$\times$ better inertia identification (7--8\% vs 52--60\%) through gradient amplification over multi-step rollouts

    \item \textbf{Fourier features} selectively improve $J_{xx}$ identification (32\% vs 60\%) through frequency matching

    \item \textbf{No architecture dominates both objectives}---prediction and identification are decoupled
\end{enumerate}

These findings establish the \textit{prediction-identification tradeoff} as a fundamental consideration in PINN architecture design. We provide guidelines for architecture selection based on application requirements, enabling practitioners to optimize for their specific objectives.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{IEEEtran}
\bibliography{references}

\end{document}
