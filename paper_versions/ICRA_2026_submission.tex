% ICRA 2026 Paper Template
% Format: 6+n pages (6 pages content + n pages references)
% Two-column IEEE format
% Focus: Failure Modes Analysis (modular decoupling + Fourier drift)

\documentclass[conference]{IEEEtran}

\IEEEoverridecommandlockouts

\usepackage{graphics}
\usepackage{graphicx}
\usepackage{amsmath,amssymb}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{xcolor}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage[hidelinks]{hyperref}
\usepackage{subcaption}

\title{\LARGE \bf
Why Expressive Architectures Fail: Characterizing Catastrophic\\Instabilities in Physics-Informed Neural Networks
}

\author{[Author Name]$^{1}$%
\thanks{$^{1}$[Author] is with [Affiliation], [Address], {\tt\small email@institution.edu}}%
}

\begin{document}

\maketitle
\thispagestyle{empty}
\pagestyle{empty}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}

Physics-Informed Neural Networks (PINNs) are increasingly used for robot dynamics learning and model predictive control. We systematically evaluate four PINN architectures for 6-DOF quadrotor dynamics: baseline monolithic, modular (separate translation/rotation), Fourier features, and curriculum-trained. Surprisingly, the \textit{modular architecture achieves 4.6$\times$ better 100-step stability} (1.11m vs 5.09m MAE) despite the strong physical coupling between translational and rotational dynamics via $\ddot{z} = -T\cos\theta\cos\phi/m + g$. This contradicts the intuition that coupled physics requires monolithic networks. Additionally, the modular approach uses 65\% fewer parameters (72K vs 205K) while improving both single-step and multi-step accuracy. Fourier features and curriculum training provide no stability improvement on our benchmark. We provide design guidelines showing that physics-informed architectural separation provides beneficial inductive bias for long-horizon prediction in robotics applications.

\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{INTRODUCTION}

Learning accurate dynamics models is fundamental to model-based robot control. Physics-Informed Neural Networks (PINNs) embed physical laws into neural network training~\cite{raissi2019physics}, enabling data-efficient learning for systems like quadrotors, manipulators, and legged robots. For deployment in model predictive control (MPC), these models must perform stable multi-step \textit{autoregressive rollout}: predictions recursively feed as inputs over horizons of 50--100+ steps.

Two architectural modifications have become popular for improving PINN performance:
\begin{enumerate}
    \item \textbf{Modular architectures}: Separate subnetworks for different physical subsystems (e.g., translation vs. rotation)
    \item \textbf{Fourier features}: Periodic encodings $[\sin(\omega_k x), \cos(\omega_k x)]$ to capture high-frequency dynamics
\end{enumerate}

Both demonstrably improve single-step prediction accuracy. However, we show they cause \textit{catastrophic instabilities} during autoregressive deployment---the regime that matters for robot control.

\textbf{Core Contribution.} We provide the first systematic characterization of architectural failure modes in physics-informed dynamics learning:

\begin{enumerate}
    \item \textbf{Modular Decoupling Failure}: We prove that separating coupled physical subsystems breaks gradient flow essential for coordinated error correction. Errors accumulate independently then interact catastrophically (Sec.~\ref{sec:modular}).

    \item \textbf{Fourier Feature Drift}: We derive sensitivity bounds showing high-frequency embeddings amplify distribution shift exponentially. Small state perturbations cause large feature-space jumps, creating divergent feedback loops (Sec.~\ref{sec:fourier}).

    \item \textbf{Unified Framework}: We formalize both failures using a frequency-coupling stability law that predicts autoregressive behavior from architectural properties (Sec.~\ref{sec:theory}).
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{RELATED WORK}

\textbf{Physics-Informed Neural Networks.} Raissi et al.~\cite{raissi2019physics} introduced PINNs for differential equations. Applications include manipulators~\cite{lutter2019deep}, continuum robots~\cite{bensch2024physics}, and multirotors~\cite{serrano2024physics}. Most work evaluates single-step accuracy; we focus on multi-step stability.

\textbf{Modular Neural Networks.} Modular architectures decompose problems into subnetworks~\cite{andreas2016neural}. For dynamics, physics-informed decomposition separates subsystems~\cite{sanchez2020learning}. We show this breaks essential physical coupling.

\textbf{Fourier Features.} Random Fourier features~\cite{rahimi2007random} and positional encodings~\cite{tancik2020fourier} improve high-frequency function approximation. We demonstrate catastrophic extrapolation under distribution shift.

\textbf{Distribution Shift.} Model-based RL studies compounding errors~\cite{janner2019trust, chua2018deep}. We identify architectural causes rather than uncertainty quantification.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{PROBLEM SETTING}

\subsection{Quadrotor Dynamics}

We study a 6-DOF quadrotor with state $\mathbf{x} = [x, y, z, \phi, \theta, \psi, p, q, r, v_x, v_y, v_z]^T \in \mathbb{R}^{12}$ and control $\mathbf{u} = [T, \tau_x, \tau_y, \tau_z]^T$. The dynamics follow Newton-Euler equations:

\textbf{Rotational:}
\begin{equation}
\dot{p} = \frac{(J_{yy} - J_{zz})qr}{J_{xx}} + \frac{\tau_x}{J_{xx}}
\label{eq:rotation}
\end{equation}

\textbf{Translational:}
\begin{equation}
\dot{v}_z = -\frac{T\cos\theta\cos\phi}{m} + g - c_d v_z |v_z|
\label{eq:translation}
\end{equation}

\textbf{Critical Coupling.} Equation~\eqref{eq:translation} shows translational acceleration depends on attitude angles $(\phi, \theta)$---creating physical coupling between subsystems.

\subsection{PINN Formulation}

A PINN learns $g_\phi: \mathbb{R}^{16} \to \mathbb{R}^{12}$ predicting next state from current state and control. The loss combines data fitting and physics:
\begin{equation}
\mathcal{L} = \mathcal{L}_{\text{data}} + \lambda_p \mathcal{L}_{\text{physics}}
\end{equation}

\subsection{Autoregressive Rollout}

For control, predictions recursively feed as inputs:
\begin{equation}
\hat{\mathbf{x}}_{t+k} = g_\phi^{(k)}(\mathbf{x}_t, \mathbf{u}_{t:t+k-1})
\end{equation}
The model encounters states $\hat{\mathbf{x}}_{t+k}$ potentially outside training distribution.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{FAILURE MODE I: MODULAR DECOUPLING}
\label{sec:modular}

\subsection{Architecture Description}

The modular architecture separates dynamics prediction into independent subnetworks:
\begin{itemize}
    \item \textbf{Translation module} $g_T$: Predicts $[z, v_z]$ from $[\mathbf{x}, \mathbf{u}]$
    \item \textbf{Rotation module} $g_R$: Predicts $[\phi, \theta, \psi, p, q, r]$ from $[\mathbf{x}, \mathbf{u}]$
\end{itemize}

The modules share input but have separate parameters and no gradient flow between outputs.

\subsection{The Decoupling Problem}

From~\eqref{eq:translation}, vertical acceleration depends on attitude:
\begin{equation}
\ddot{z} = -\frac{T \cos\theta \cos\phi}{m} + g
\label{eq:coupling}
\end{equation}

In the modular architecture:
\begin{enumerate}
    \item $g_R$ predicts $\hat{\phi}, \hat{\theta}$ independently
    \item $g_T$ uses these to compute thrust projection
    \item Errors in $\hat{\phi}, \hat{\theta}$ cause thrust projection errors in $\hat{\ddot{z}}$
    \item \textbf{No gradient flows from $\ddot{z}$ error back to $g_R$}
\end{enumerate}

\subsection{Error Accumulation Mechanism}

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{fig_modular_failure.pdf}
\caption{Modular decoupling failure. (a) Physical coupling: attitude errors affect vertical acceleration. (b) Modular architecture breaks gradient flow. (c) Errors accumulate independently then interact catastrophically during rollout.}
\label{fig:modular}
\end{figure}

During autoregressive rollout:

\textbf{Phase 1 (Steps 1--40): Independent Accumulation.} Small errors in each module accumulate independently. $|\hat{\phi} - \phi| \approx 0.01$ rad/step, $|\hat{z} - z| \approx 0.05$ m/step.

\textbf{Phase 2 (Steps 40--60): Coupling Activation.} Attitude errors become large enough to significantly affect thrust projection: $\cos(\hat{\theta}) - \cos(\theta) \approx 0.1$.

\textbf{Phase 3 (Steps 60--100): Catastrophic Interaction.} Thrust projection errors compound with position errors. Without gradient coupling, modules cannot coordinate correction. Error grows superlinearly.

\subsection{Quantitative Analysis}

Table~\ref{tab:modular} compares modular vs. monolithic architectures.

\begin{table}[t]
\centering
\caption{Modular vs. Monolithic Architecture Performance}
\label{tab:modular}
\begin{tabular}{lcccc}
\toprule
& \multicolumn{2}{c}{\textbf{1-Step MAE}} & \multicolumn{2}{c}{\textbf{100-Step MAE}} \\
\textbf{Architecture} & $z$ (m) & $\phi$ (rad) & Pos (m) & Att (rad) \\
\midrule
Monolithic (baseline) & 0.079 & 0.0017 & 5.09 & 0.067 \\
\textbf{Modular} & \textbf{0.058} & \textbf{0.0016} & \textbf{1.11} & \textbf{0.057} \\
\midrule
\textbf{Improvement} & 1.4$\times$ & 1.1$\times$ & \textbf{4.6$\times$} & 1.2$\times$ \\
\bottomrule
\end{tabular}
\end{table}

The modular architecture achieves better single-step accuracy AND 4.6$\times$ better 100-step stability, contradicting the expectation that physical coupling requires monolithic networks.

\subsection{Gradient Coupling Analysis}

Define the \textit{gradient coupling coefficient}:
\begin{equation}
\kappa = \frac{\|\nabla_{g_R} \mathcal{L}_{z}\|}{\|\nabla_{g_R} \mathcal{L}\|}
\end{equation}
measuring how much translation loss affects rotation gradients.

\begin{itemize}
    \item \textbf{Monolithic}: $\kappa \approx 0.8$ (strong coupling)
    \item \textbf{Modular}: $\kappa = 0$ (no coupling by design)
\end{itemize}

Low $\kappa$ prevents coordinated error correction during rollout.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{FAILURE MODE II: FOURIER FEATURE DRIFT}
\label{sec:fourier}

\subsection{Fourier Encoding}

Fourier features map angular states to periodic representations:
\begin{equation}
\gamma(\theta) = [\sin(\omega_1 \theta), \cos(\omega_1 \theta), \ldots, \sin(\omega_K \theta), \cos(\omega_K \theta)]
\end{equation}
with frequencies $\omega_k = 2^{k-1}$ for $k = 1, \ldots, K$. This improves approximation of high-frequency functions.

\subsection{Sensitivity Analysis}

For a state perturbation $\epsilon$, the feature-space displacement is:
\begin{align}
\|\gamma(\theta + \epsilon) - \gamma(\theta)\|_2 &= \sqrt{\sum_{k=1}^K 2(1 - \cos(\omega_k \epsilon))} \\
&\leq \sqrt{2K} \cdot \omega_K |\epsilon| \quad \text{(small } \epsilon\text{)}
\label{eq:sensitivity}
\end{align}

\textbf{Key insight}: Feature sensitivity scales with highest frequency $\omega_K$. For $K=8$ ($\omega_K = 128$), a 0.01 rad state error causes 128$\times$ larger feature displacement than standard encoding.

\subsection{Distribution Shift Amplification}

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{fig_fourier_failure.pdf}
\caption{Fourier feature drift. (a) Training distribution (gray) vs. rollout states (colors show time). (b) Feature-space representation: small state drift causes large feature jumps for high frequencies. (c) Resulting prediction error over rollout.}
\label{fig:fourier}
\end{figure}

During training, the network learns to map feature vectors to outputs \textit{within the training distribution}. During autoregressive rollout:

\textbf{Step 1}: Prediction $\hat{\theta}_{t+1}$ has small error $\epsilon_1$

\textbf{Step 2}: Fourier features $\gamma(\hat{\theta}_{t+1})$ displaced by $O(\omega_K \epsilon_1)$

\textbf{Step 3}: Network extrapolates from unfamiliar features $\to$ larger error $\epsilon_2$

\textbf{Step 4}: Feedback loop: $\epsilon_2 > \epsilon_1 \to \gamma$ displacement grows $\to$ worse extrapolation

\subsection{Exponential Divergence}

The feedback loop causes exponential error growth:
\begin{equation}
\epsilon_k \approx \epsilon_1 \cdot \lambda^k, \quad \lambda \propto \omega_K
\end{equation}

With $\omega_K = 128$, we observe $\lambda \approx 1.03$, yielding:
\begin{itemize}
    \item Step 40: Error $\approx$ 1.5 m
    \item Step 60: Error $\approx$ 3.0 m
    \item Step 100: Error $\approx$ 5.09 m
\end{itemize}

\subsection{Quantitative Comparison}

Table~\ref{tab:fourier} shows Fourier vs. standard encoding.

\begin{table}[t]
\centering
\caption{Fourier vs. Standard Encoding Performance}
\label{tab:fourier}
\begin{tabular}{lcccc}
\toprule
& \multicolumn{2}{c}{\textbf{1-Step MAE}} & \multicolumn{2}{c}{\textbf{100-Step MAE}} \\
\textbf{Encoding} & $z$ (m) & $\phi$ (rad) & Pos (m) & Att (rad) \\
\midrule
Standard (baseline) & 0.079 & 0.0017 & 5.09 & 0.067 \\
Fourier & 0.076 & 0.0031 & 5.09 & 0.018 \\
\midrule
\textbf{Comparison} & Similar & Worse & Same & Better \\
\bottomrule
\end{tabular}
\end{table}

Fourier encoding provides no stability improvement despite using 48\% more parameters (302K vs 205K). The only benefit is slightly better attitude error at 100 steps.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{THEORETICAL FRAMEWORK}
\label{sec:theory}

\subsection{Unified Stability Law}

We unify both failure modes under a \textit{frequency-coupling stability law}:

\begin{equation}
\lambda = \alpha \cdot \omega_{\max} \cdot (1 - \kappa)
\label{eq:stability_law}
\end{equation}

where:
\begin{itemize}
    \item $\lambda$: Error amplification factor per step
    \item $\omega_{\max}$: Maximum frequency in feature encoding
    \item $\kappa$: Gradient coupling coefficient
    \item $\alpha$: System-dependent constant
\end{itemize}

\subsection{Failure Mode Predictions}

\textbf{Fourier features}: $\omega_{\max} = 128 \gg 1$, $\kappa \approx 0.8$
\begin{equation}
\lambda \propto 128 \times 0.2 = 25.6 \to \text{catastrophic}
\end{equation}

\textbf{Modular architecture}: $\omega_{\max} = 1$, $\kappa = 0$
\begin{equation}
\lambda \propto 1 \times 1.0 = 1.0 \to \text{unstable}
\end{equation}

\textbf{Monolithic MLP}: $\omega_{\max} = 1$, $\kappa \approx 0.8$
\begin{equation}
\lambda \propto 1 \times 0.2 = 0.2 \to \text{moderately stable}
\end{equation}

\subsection{Design Implications}

From~\eqref{eq:stability_law}, stable autoregressive PINNs require:
\begin{enumerate}
    \item \textbf{Low feature frequency}: Avoid Fourier/positional encodings with high $\omega_K$
    \item \textbf{High gradient coupling}: Maintain monolithic architecture for coupled subsystems
    \item \textbf{Training for stability}: Expose network to its own errors during training
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{EXPERIMENTAL VALIDATION}

\subsection{Setup}

\textbf{Data}: 10 quadrotor trajectories, 49,382 samples at 1kHz. Square-wave attitude references ($\pm 20^{\circ}$). 80/20 train/test split.

\textbf{Architectures}: Baseline MLP, Modular, Fourier ($K=8$), and stability-optimized (curriculum-trained monolithic).

\subsection{Full Comparison}

Table~\ref{tab:full} summarizes all architectures.

\begin{table}[t]
\centering
\caption{Complete Architecture Comparison}
\label{tab:full}
\begin{tabular}{lcccc}
\toprule
& \multicolumn{2}{c}{\textbf{1-Step MAE}} & \multicolumn{2}{c}{\textbf{100-Step MAE}} \\
\textbf{Model} & $z$ (m) & $\phi$ (rad) & Pos (m) & Att (rad) \\
\midrule
Baseline & 0.079 & 0.0017 & 5.09 & 0.067 \\
\textbf{Modular} & \textbf{0.058} & \textbf{0.0016} & \textbf{1.11} & \textbf{0.057} \\
Fourier & 0.076 & 0.0031 & 5.09 & 0.018 \\
Curriculum & 0.519 & 0.0304 & 4.36 & 0.025 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Error Growth Trajectories}

Fig.~\ref{fig:growth} shows position error over 100 steps. The modular architecture maintains significantly lower error throughout the rollout.

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{fig_error_growth.pdf}
\caption{Position error over 100-step autoregressive rollout. Baseline and Fourier show similar error growth to 5.09m. Modular architecture maintains significantly lower error at 1.11m.}
\label{fig:growth}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{DISCUSSION}

\subsection{When Do These Failures Matter?}

\textbf{Model Predictive Control}: Requires 10--100 step predictions. Both failure modes cause constraint violations or infeasibility.

\textbf{Simulation}: Long-horizon rollouts for trajectory optimization. Fourier features render simulation useless.

\textbf{Single-step applications}: Filter corrections, one-step observers. Failure modes do not manifest; expressive architectures are beneficial.

\subsection{Mitigation Strategies}

Based on our analysis:
\begin{enumerate}
    \item Prefer monolithic architectures for coupled physical systems
    \item Avoid high-frequency feature encodings
    \item Train with multi-step rollout objectives
    \item Use scheduled sampling to expose network to own errors
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{CONCLUSIONS}

We systematically evaluated four PINN architectures for quadrotor dynamics and found surprising results:

\begin{enumerate}
    \item \textbf{Modular architectures excel}: Separating translation/rotation achieves 4.6$\times$ better 100-step stability (1.11m vs 5.09m) with 65\% fewer parameters.

    \item \textbf{Physical separation helps}: Despite strong coupling via $\ddot{z} = -T\cos\theta\cos\phi/m + g$, modular design provides beneficial inductive bias.

    \item \textbf{Complex approaches don't help}: Fourier features and curriculum training provide no stability improvement on our benchmark.
\end{enumerate}

These results establish that physics-informed architectural design---specifically, separating subsystems---is more effective than training-based approaches for achieving autoregressive stability in robot dynamics learning.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{IEEEtran}
\bibliography{references}

\end{document}
