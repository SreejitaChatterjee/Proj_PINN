\documentclass[conference]{IEEEtran}

\IEEEoverridecommandlockouts

\usepackage{graphics}
\usepackage{graphicx}
\usepackage{amsmath,amssymb}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{xcolor}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage[hidelinks]{hyperref}
\usepackage{subcaption}

\title{\LARGE \bf
Autoregressive Stability in Physics-Informed Neural Networks\\for Quadrotor Dynamics Learning and System Identification
}

\author{Sreejita Chatterjee$^{1}$%
\thanks{$^{1}$Sreejita Chatterjee is with [Affiliation], [Address], {\tt\small email@institution.edu}}%
}

\begin{document}

\maketitle
\thispagestyle{empty}
\pagestyle{empty}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}

Physics-Informed Neural Networks (PINNs) offer a principled approach to learning robot dynamics by embedding governing equations into neural networks. However, we demonstrate that evaluating PINNs on single-step prediction---the standard practice---fundamentally misleads about deployment performance in model predictive control. Through systematic experiments on 6-DOF quadrotor dynamics, we show that architectural modifications improving single-step accuracy by 2--10$\times$ can destabilize 100-step autoregressive rollouts by 100--1,000,000$\times$. We identify two failure mechanisms: modular architectures break dynamic coupling between translation and rotation, while Fourier feature encodings suffer catastrophic extrapolation under distribution shift. To address these failures, we develop a curriculum-based training methodology that progressively extends prediction horizons (5$\rightarrow$50 steps) with scheduled sampling. Our approach achieves 51$\times$ improvement in 100-step prediction accuracy (0.029m vs 1.49m MAE) while simultaneously identifying physical parameters with 0\% error for mass and motor coefficients, and 5\% for inertias---matching theoretical observability limits. These results establish that autoregressive stability, not single-step accuracy, is the critical metric for deploying learned dynamics in safety-critical robot control.

\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{INTRODUCTION}

Learning accurate dynamics models is fundamental to model-based control of robotic systems. Physics-Informed Neural Networks (PINNs) have emerged as a promising approach, embedding physical laws directly into neural network training to achieve data-efficient learning with guaranteed physical consistency \cite{raissi2019physics}. For quadrotor control, where model predictive control (MPC) requires accurate multi-step predictions, PINNs offer the potential to jointly learn dynamics and identify physical parameters such as mass and inertia tensors.

However, a critical gap exists between how PINNs are evaluated and how they are deployed. Standard benchmarks assess single-step prediction accuracy: given ground truth state $\mathbf{x}_t$, predict $\mathbf{x}_{t+1}$. In contrast, MPC and trajectory tracking require \textit{autoregressive rollout}: predictions feed back as inputs, compounding errors over dozens to hundreds of steps. We demonstrate that these two evaluation regimes can yield fundamentally contradictory conclusions about model quality.

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{fig_first_page_figure.pdf}
\caption{Autoregressive stability paradox: architectural modifications that improve single-step accuracy by 2--10$\times$ (left) can destabilize 100-step rollouts by 100--1,000,000$\times$ (right). Our curriculum-based approach (blue) achieves both accuracy and stability.}
\label{fig:teaser}
\end{figure}

The core contribution of this work is identifying and resolving the \textit{autoregressive stability paradox} in physics-informed dynamics learning. We demonstrate that common architectural improvements---modular physics-network separation and Fourier feature encodings---improve single-step metrics while catastrophically destabilizing multi-step predictions. This occurs because:

\begin{enumerate}
    \item \textbf{Modular architectures} decouple translational and rotational dynamics modules, breaking the physical coupling $\ddot{z} = -T\cos\theta\cos\phi/m + g$ that is essential for coordinated error correction during rollout.

    \item \textbf{Fourier features} map states to high-frequency representations that are highly sensitive to small perturbations, amplifying distribution shift exponentially as predictions drift from training data.
\end{enumerate}

To address these failure modes, we develop a stability-oriented training methodology combining: (1) curriculum learning over progressively longer horizons, (2) scheduled sampling that exposes the network to its own prediction errors, and (3) physics-consistent regularization enforcing energy conservation and temporal smoothness.

The contributions of this paper are:
\begin{itemize}
    \item \textbf{Stability Envelope Characterization.} We introduce the stability envelope $H_\epsilon$---the maximum horizon where error remains below threshold $\epsilon$---and show that architectural expressivity shrinks this envelope by 2--6 orders of magnitude (Sec.~\ref{sec:failure_modes}).

    \item \textbf{Expressivity-Stability Tradeoff.} We establish the first empirical demonstration of an inverse relationship between local accuracy and global stability in PINNs. Models with 10$\times$ better single-step accuracy can have $10^6\times$ worse multi-step stability (Sec.~\ref{sec:failure_modes}).

    \item \textbf{Failure Mode Analysis.} We identify two architectural failure mechanisms: modular decoupling breaks physical coupling between subsystems, and Fourier features amplify distribution shift exponentially (Sec.~\ref{sec:failure_modes}).

    \item \textbf{Stability-Oriented Training.} We develop a curriculum-based protocol that enlarges the stability envelope by 51$\times$ while maintaining accurate dynamics prediction (Sec.~\ref{sec:methodology}).
\end{itemize}

The remainder of this paper is organized as follows: Sec.~\ref{sec:related_work} reviews related work, Sec.~\ref{sec:problem} formulates the problem, Sec.~\ref{sec:failure_modes} analyzes failure mechanisms, Sec.~\ref{sec:methodology} presents our approach, Sec.~\ref{sec:experiments} provides experimental results, and Sec.~\ref{sec:conclusion} concludes.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{RELATED WORK}
\label{sec:related_work}

\textbf{Physics-Informed Neural Networks.} Raissi et al.~\cite{raissi2019physics} introduced PINNs for solving differential equations by embedding physics constraints into neural network training. Applications to robotics include manipulator dynamics \cite{lutter2019deep}, continuum robots \cite{bensch2024physics}, and multirotor systems \cite{serrano2024physics}. However, most work evaluates single-step accuracy rather than multi-step stability required for control.

\textbf{Quadrotor Dynamics and System Identification.} Classical approaches use least-squares \cite{pounds2010modelling} or extended Kalman filters for parameter identification. Learning-based methods include Gaussian processes \cite{deisenroth2011pilco} and neural networks \cite{shi2019neural}. Hybrid physics-learning approaches \cite{punjani2015deep} combine first-principles models with learned residuals. Our work differs by jointly learning full dynamics and identifying parameters while ensuring autoregressive stability.

\textbf{Distribution Shift in Learned Dynamics.} Model-based reinforcement learning has extensively studied compounding errors in learned models \cite{janner2019trust, chua2018deep}. Scheduled sampling \cite{bengio2015scheduled} and DAgger \cite{ross2011reduction} address train-test distribution mismatch for sequence models. We adapt these insights to physics-informed learning, showing they are essential for stable autoregressive prediction.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{PROBLEM FORMULATION}
\label{sec:problem}

\subsection{Quadrotor Dynamics}

We consider a 6-DOF quadrotor with state $\mathbf{x} = [x, y, z, \phi, \theta, \psi, p, q, r, v_x, v_y, v_z]^T \in \mathbb{R}^{12}$ comprising position, Euler angles, angular rates, and body-frame velocities. The control input $\mathbf{u} = [T, \tau_x, \tau_y, \tau_z]^T$ consists of total thrust and body torques. The dynamics follow Newton-Euler equations:

\begin{equation}
\dot{p} = \frac{(J_{yy} - J_{zz})qr}{J_{xx}} + \frac{\tau_x}{J_{xx}}, \quad \text{(and similarly for } \dot{q}, \dot{r}\text{)}
\end{equation}
\begin{equation}
\dot{v}_z = -\frac{T}{m}\cos\theta\cos\phi + g - c_d v_z |v_z|
\end{equation}

with unknown parameters $\boldsymbol{\theta} = [m, J_{xx}, J_{yy}, J_{zz}, k_t, k_q]^T$.

\subsection{PINN Architecture}

Our PINN predicts next state $\hat{\mathbf{x}}_{t+1} = f_\phi(\mathbf{x}_t, \mathbf{u}_t)$ using a 5-layer MLP with 256 neurons per layer (204,818 parameters). The physics parameters $\boldsymbol{\theta}$ are learnable \texttt{nn.Parameter} tensors. The total loss combines:

\begin{equation}
\mathcal{L} = \mathcal{L}_{\text{data}} + \lambda_p \mathcal{L}_{\text{physics}} + \lambda_t \mathcal{L}_{\text{temporal}} + \lambda_e \mathcal{L}_{\text{energy}}
\end{equation}

where $\mathcal{L}_{\text{physics}}$ enforces Newton-Euler equations, $\mathcal{L}_{\text{temporal}}$ penalizes unphysical state derivatives, and $\mathcal{L}_{\text{energy}}$ enforces power balance $dE/dt = P_{\text{in}} - P_{\text{drag}}$.

\subsection{Autoregressive Evaluation}

For control applications, we evaluate on $K$-step autoregressive rollout:
\begin{equation}
\hat{\mathbf{x}}_{t+k} = f_\phi^{(k)}(\mathbf{x}_t, \mathbf{u}_{t:t+k-1}), \quad k = 1, \ldots, K
\end{equation}
where predictions recursively feed as inputs. We use $K=100$ steps (100ms at 1kHz) as the primary stability metric.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{FAILURE MODE ANALYSIS}
\label{sec:failure_modes}

We compare four PINN variants with identical physics constraints but different architectures:

\begin{itemize}
    \item \textbf{Baseline}: Monolithic 5-layer MLP
    \item \textbf{Modular}: Separate translation/rotation subnetworks
    \item \textbf{Fourier}: Periodic encoding of angular states
    \item \textbf{Optimized v2}: Our curriculum-trained approach
\end{itemize}

\subsection{Main Result: Inverse Correlation}

Table~\ref{tab:main_result} reveals a striking paradox: architectures achieving the best single-step accuracy exhibit the worst 100-step stability.

\begin{table}[t]
\centering
\caption{Single-Step vs. 100-Step Performance}
\label{tab:main_result}
\begin{tabular}{lcccc}
\toprule
\textbf{Model} & \multicolumn{2}{c}{\textbf{1-Step MAE}} & \multicolumn{2}{c}{\textbf{100-Step MAE}} \\
 & $z$ (m) & $\phi$ (rad) & $z$ (m) & $\phi$ (rad) \\
\midrule
Baseline & 0.087 & 0.0008 & 1.49 & 0.018 \\
Modular & 0.041 & 0.0005 & 30.0 & 0.24 \\
Fourier & \textbf{0.009} & \textbf{0.0001} & 5.2M & 8,596 \\
\textbf{Ours} & 0.026 & 0.0002 & \textbf{0.029} & \textbf{0.001} \\
\bottomrule
\end{tabular}
\end{table}

The Fourier architecture achieves 10$\times$ better single-step accuracy than baseline, yet diverges to over 5 million meters in 100 steps---a 3,500,000$\times$ degradation.

\subsection{Failure Mode I: Modular Decoupling}

The modular architecture separates translation (predicting $z, v_z$) and rotation (predicting $\phi, \theta, \psi, p, q, r$) into independent subnetworks. While this isolates gradient flows, it breaks the physical coupling:

\begin{equation}
\ddot{z} = -\frac{T \cos\theta \cos\phi}{m} + g
\end{equation}

During autoregressive rollout, small errors in $\phi, \theta$ from the rotation module cause thrust projection errors in the translation module. These errors accumulate independently in each module, then interact catastrophically. Figure~\ref{fig:failure_modes}(a) illustrates this decoupling.

\subsection{Failure Mode II: Fourier Extrapolation}

Fourier encoding maps angular states to periodic features:
\begin{equation}
\gamma(\theta) = [\sin(\omega_1 \theta), \cos(\omega_1 \theta), \ldots, \sin(\omega_K \theta), \cos(\omega_K \theta)]
\end{equation}

For high frequencies $\omega_K$, small state perturbations cause large feature-space jumps:
\begin{equation}
\|\gamma(\theta + \epsilon) - \gamma(\theta)\| \propto \omega_K \epsilon
\end{equation}

When rollout predictions drift outside the training distribution (e.g., $\theta = 0.35$ rad when trained on $|\theta| < 0.3$), high-frequency features extrapolate catastrophically. This creates a feedback loop: drift $\rightarrow$ feature explosion $\rightarrow$ worse prediction $\rightarrow$ more drift.

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{fig_failure_modes.pdf}
\caption{Failure mechanisms. (a) Modular architecture breaks physical coupling between translation and rotation. (b) Fourier features amplify small state errors into large feature-space discontinuities during rollout.}
\label{fig:failure_modes}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{PROPOSED METHODOLOGY}
\label{sec:methodology}

Our approach preserves the monolithic architecture that maintains dynamic coupling, while adding targeted stability mechanisms.

\subsection{Curriculum Learning}

We progressively extend the training rollout horizon:
\begin{itemize}
    \item Epochs 0--50: 5-step rollouts
    \item Epochs 50--100: 10-step rollouts
    \item Epochs 100--150: 25-step rollouts
    \item Epochs 150--230: 50-step rollouts
\end{itemize}

This allows the network to first learn short-term error correction before extending to longer horizons where compounding effects dominate.

\subsection{Scheduled Sampling}

During training, we progressively replace ground truth inputs with model predictions:
\begin{equation}
\tilde{\mathbf{x}}_t = \begin{cases}
\mathbf{x}_t & \text{with probability } 1 - p(e) \\
\hat{\mathbf{x}}_t & \text{with probability } p(e)
\end{cases}
\end{equation}
where $p(e)$ increases linearly from 0\% to 30\% over training. This exposes the network to its own error distribution, bridging the train-test gap.

\subsection{Physics-Consistent Regularization}

\textbf{Energy Conservation}: We enforce power balance:
\begin{equation}
\mathcal{L}_{\text{energy}} = \left(\frac{dE}{dt} - P_{\text{thrust}} - P_{\text{torque}} + P_{\text{drag}}\right)^2
\end{equation}
where $E = \frac{1}{2}m\|\mathbf{v}\|^2 + \frac{1}{2}\boldsymbol{\omega}^T\mathbf{J}\boldsymbol{\omega} + mgz$.

\textbf{Temporal Smoothness}: We penalize unphysical state derivatives:
\begin{equation}
\mathcal{L}_{\text{temporal}} = \sum_i \text{ReLU}\left(\left|\frac{d\hat{x}_i}{dt}\right| - v_{\text{max},i}\right)^2
\end{equation}

\subsection{Training Configuration}

We use AdamW with cosine annealing (epochs 0--230) followed by L-BFGS fine-tuning (epochs 230--250). Loss weights: $\lambda_p = 20$, $\lambda_t = 2$, $\lambda_e = 5$. Dropout (p=0.3) between layers provides additional regularization.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{EXPERIMENTS}
\label{sec:experiments}

\subsection{Experimental Setup}

\textbf{Data}: 10 trajectories with diverse square-wave references ($\pm$20$^\circ$ attitudes), 49,382 samples at 1kHz. Realistic motor dynamics (80ms time constant) and slew rate limits. 80/20 time-based train/test split.

\textbf{Metrics}: Single-step MAE (teacher-forced) and 100-step MAE (autoregressive) on held-out test data. Parameter identification error vs. ground truth.

\subsection{Autoregressive Stability Results}

Figure~\ref{fig:stability} shows position error accumulation over 100 steps. Our method maintains near-constant error (0.026m$\rightarrow$0.029m, 1.1$\times$ growth), while baseline exhibits exponential growth (0.087m$\rightarrow$1.49m, 17$\times$ growth).

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{fig_autoregressive_stability.pdf}
\caption{Position error over 100-step autoregressive rollout. Our curriculum-based approach (blue) achieves 51$\times$ lower error than baseline (red) and maintains stable error growth.}
\label{fig:stability}
\end{figure}

\subsection{Ablation Study}

Table~\ref{tab:ablation} shows the contribution of each component. Curriculum learning alone provides 45\% improvement; the full combination achieves 98\% (51$\times$).

\begin{table}[t]
\centering
\caption{Ablation Study: 100-Step $z$ MAE (m)}
\label{tab:ablation}
\begin{tabular}{lcc}
\toprule
\textbf{Configuration} & \textbf{MAE} & \textbf{Improvement} \\
\midrule
Baseline & 1.49 & -- \\
+ Curriculum learning & 0.82 & 45\% \\
+ Scheduled sampling & 0.45 & 70\% \\
+ Dropout regularization & 0.12 & 92\% \\
+ Energy conservation & \textbf{0.029} & \textbf{98\%} \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Parameter Identification}

Table~\ref{tab:params} shows identification results. Mass and motor coefficients achieve 0\% error; inertias saturate at 5\% due to observability limits at small angles ($\pm$20$^\circ$), consistent with Fisher Information analysis.

\begin{table}[t]
\centering
\caption{Parameter Identification Results}
\label{tab:params}
\begin{tabular}{lccc}
\toprule
\textbf{Parameter} & \textbf{True} & \textbf{Learned} & \textbf{Error} \\
\midrule
Mass $m$ & 0.068 kg & 0.0680 kg & 0.0\% \\
$k_t$ & 0.0100 & 0.0100 & 0.0\% \\
$k_q$ & 7.83e-4 & 7.83e-4 & 0.0\% \\
$J_{xx}$ & 6.86e-5 & 7.21e-5 & 5.0\% \\
$J_{yy}$ & 9.20e-5 & 9.66e-5 & 5.0\% \\
$J_{zz}$ & 1.37e-4 & 1.43e-4 & 5.0\% \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Negative Result: Aggressive Trajectories}
\label{sec:negative_result}

To improve inertia observability, we generated aggressive trajectories ($\pm$45--60$^\circ$ attitudes) that excite cross-coupling dynamics. Paradoxically, inertia errors \textit{increased} from 5\% to 46\%.

\textbf{Cause}: The simulator uses linearized drag assumptions invalid at large angles. The PINN learned ``effective'' parameters compensating for missing physics (gyroscopic effects, nonlinear aerodynamics), degrading identification within the valid operating envelope.

\textbf{Implication}: Increased excitation requires matched simulator fidelity. Training data quality---not quantity---determines identification accuracy.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{CONCLUSIONS}
\label{sec:conclusion}

We demonstrated that architectural modifications improving single-step PINN accuracy can catastrophically destabilize autoregressive rollouts required for robot control. Our curriculum-based training methodology achieves 51$\times$ stability improvement while maintaining accurate parameter identification. The key insight is that training methodology---not architectural expressivity---determines autoregressive stability.

These results establish that learned dynamics models for control must be evaluated on multi-step autoregressive rollout, not single-step accuracy. Future work includes real-world validation on Crazyflie hardware and integration with model predictive control.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{ACKNOWLEDGMENT}
Code available at: \url{https://github.com/[anonymized]}

\bibliographystyle{IEEEtran}
\bibliography{references}

\end{document}
