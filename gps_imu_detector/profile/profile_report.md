# Profiling Report: GPS-IMU Anomaly Detector

**Date:** [TO BE FILLED]
**Commit:** [TO BE FILLED]
**Author:** [TO BE FILLED]

---

## 1. Hardware Specification

| Component | Specification |
|-----------|---------------|
| CPU | [e.g., Intel Core i7-10700 @ 2.90GHz] |
| Cores | [e.g., 8 cores, 16 threads] |
| RAM | [e.g., 32 GB DDR4] |
| OS | [e.g., Ubuntu 22.04 / Windows 11] |
| Python | [e.g., 3.10.12] |
| PyTorch | [e.g., 2.1.0] |
| ONNX Runtime | [e.g., 1.16.0] |

---

## 2. Model Specification

| Property | Value |
|----------|-------|
| Architecture | 1D CNN + GRU |
| Conv Channels | 32 → 64 |
| GRU Hidden | 64 |
| Total Parameters | [TO BE MEASURED] |
| Model Size (FP32) | [TO BE MEASURED] |
| Model Size (INT8) | [TO BE MEASURED] |

---

## 3. Latency Benchmarks

### 3.1 PyTorch (FP32)

| Metric | Value |
|--------|-------|
| Mean | [TO BE MEASURED] ms |
| Std | [TO BE MEASURED] ms |
| P50 | [TO BE MEASURED] ms |
| P95 | [TO BE MEASURED] ms |
| P99 | [TO BE MEASURED] ms |
| Max | [TO BE MEASURED] ms |
| Samples | [e.g., 1000] |
| Warmup | [e.g., 50] |

### 3.2 ONNX Runtime (FP32)

| Metric | Value |
|--------|-------|
| Mean | [TO BE MEASURED] ms |
| P50 | [TO BE MEASURED] ms |
| P99 | [TO BE MEASURED] ms |
| Threads | 1 (single-thread) |

### 3.3 ONNX Runtime (INT8 Quantized)

| Metric | Value |
|--------|-------|
| Mean | [TO BE MEASURED] ms |
| P50 | [TO BE MEASURED] ms |
| P99 | [TO BE MEASURED] ms |
| Speedup vs FP32 | [TO BE MEASURED]x |

### 3.4 Full Pipeline (Feature Extraction + Inference)

| Component | Latency (ms) | % of Total |
|-----------|--------------|------------|
| Feature Extraction | [TO BE MEASURED] | [%] |
| Physics Residuals | [TO BE MEASURED] | [%] |
| EKF Update | [TO BE MEASURED] | [%] |
| CNN-GRU Inference | [TO BE MEASURED] | [%] |
| Hybrid Scoring | [TO BE MEASURED] | [%] |
| **Total** | [TO BE MEASURED] | 100% |

---

## 4. Memory Footprint

| Metric | Value |
|--------|-------|
| Peak CPU Memory | [TO BE MEASURED] MB |
| Model Memory (FP32) | [TO BE MEASURED] MB |
| Model Memory (INT8) | [TO BE MEASURED] MB |
| Feature Buffer | [TO BE MEASURED] MB |
| Total Working Set | [TO BE MEASURED] MB |

---

## 5. Quantization Analysis

### 5.1 Accuracy Impact

| Metric | FP32 | INT8 | Drop |
|--------|------|------|------|
| AUROC | [TO BE MEASURED] | [TO BE MEASURED] | [%] |
| Recall@5%FPR | [TO BE MEASURED] | [TO BE MEASURED] | [%] |
| Worst-Case Recall | [TO BE MEASURED] | [TO BE MEASURED] | [%] |

### 5.2 Quantization Steps

1. Dynamic quantization (PyTorch):
   ```python
   torch.quantization.quantize_dynamic(model, {nn.Linear, nn.GRU}, dtype=torch.qint8)
   ```

2. ONNX export:
   ```python
   torch.onnx.export(model, dummy_input, "model.onnx", opset_version=13)
   ```

3. ONNX quantization:
   ```python
   from onnxruntime.quantization import quantize_dynamic
   quantize_dynamic("model.onnx", "model_int8.onnx")
   ```

---

## 6. Target Compliance

| Target | Requirement | Measured | Status |
|--------|-------------|----------|--------|
| Latency | ≤5 ms/timestep | [TO BE MEASURED] | [PASS/FAIL] |
| Model Size | <1 MB | [TO BE MEASURED] | [PASS/FAIL] |
| Accuracy Drop | ≤2% absolute | [TO BE MEASURED] | [PASS/FAIL] |
| Memory | <100 MB | [TO BE MEASURED] | [PASS/FAIL] |

---

## 7. Latency CDF

```
[TO BE GENERATED: Latency CDF plot showing P50, P95, P99 markers]

Percentile | Latency (ms)
-----------|-------------
P10        | [TO BE MEASURED]
P25        | [TO BE MEASURED]
P50        | [TO BE MEASURED]
P75        | [TO BE MEASURED]
P90        | [TO BE MEASURED]
P95        | [TO BE MEASURED]
P99        | [TO BE MEASURED]
```

---

## 8. Profiling Commands

```bash
# Run latency benchmark
python src/quantization.py --benchmark --n_iterations 1000

# Run full pipeline profile
python src/operational_metrics.py --profile --output profile/

# Generate ONNX and benchmark
python src/quantization.py --export onnx --quantize int8 --benchmark

# Memory profile
python -m memory_profiler src/inference.py --profile
```

---

## 9. Notes

- All benchmarks run with single thread (OMP_NUM_THREADS=1)
- Warmup iterations excluded from timing
- Measurements averaged over [N] runs
- [Any additional notes about the profiling environment]

---

## 10. Conclusion

[TO BE FILLED: Summary of whether the detector meets all targets and is ready for deployment]

---

*Report generated by: [script/manual]*
*Last updated: [date]*
